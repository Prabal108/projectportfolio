<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VR Research Portfolio | HP Omnicept & Muse S Athena</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Exo+2:wght@300;400;500;600;700&family=Share+Tech+Mono&display=swap" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.11.4/gsap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.11.4/ScrollTrigger.min.js"></script>
    <link rel="stylesheet" href="style.css">
    
      
    
</head>
<body>
    <!-- Particle Background -->
    <canvas id="particle-canvas"></canvas>

    <!-- Header & Navigation -->
    <header>
        <div class="container">
            <nav>
                <a href="#" class="logo">VR<span>NeuroLab</span></a>
                <ul class="nav-links">
                    <li><a href="#home">Home</a></li>
                    <li><a href="#about">About</a></li>
                    <li><a href="#research">Research</a></li>
                    <li><a href="#input-output">Methodology</a></li>
                    <li><a href="#contact">Contact</a></li>
                </ul>
                <div class="menu-btn">
                    <i class="fas fa-bars"></i>
                </div>
            </nav>
        </div>
    </header>

    <!-- Home Section -->
    <section id="home">
        <div class="container">
            <div class="home-content">
                <div class="hero-text">
                    <h1>Neuro-Adaptive VR Experiences</h1>
                    <p>Pioneering research at the intersection of virtual reality and neuroscience, utilizing HP Omnicept and Muse S Athena to create responsive, adaptive virtual environments.</p>
                    <a href="#research" class="btn">Explore Research</a>
                </div>
                <div class="hero-visual">
                    <div class="vr-headset"></div>
                </div>
            </div>
        </div>
    </section>

    <!-- About Section -->
    <section id="about">
        <div class="container">
            <h2 class="section-title">About The Research</h2>
            <div class="about-content">
                <div class="about-text">
                    <p>Architecture significantly impacts human well-being, emotions, and cognitive states, as supported by multiple architectural theories. Biophilic Design and Attention Restoration Theory suggest that natural elements in spaces can reduce stress and enhance focus. Prospect-Refuge Theory emphasizes the need for balance between openness and safety, while Neuroarchitecture and Evidence-Based Design link spatial configurations with measurable brain and physiological responses.

By using Virtual Reality (VR) combined with EEG, fNIRS, and PPG, this project provides a scientific framework to objectively evaluate how architectural variables—such as geometry, color, openness, and biophilic elements—affect human relaxation, engagement, and cognitive performance. This approach bridges traditional design theories with quantifiable biomedical evidence for wellness-oriented architectural design.

Architecture has a profound impact on human wellness, emotions, and cognitive states, supported by more than 15 architectural theories that link spatial design with human well-being. These theories emphasize factors like nature integration, spatial balance, cognitive comfort, and stress recovery. By integrating Virtual Reality (VR) with EEG, fNIRS, and PPG, this project aims to provide quantifiable evidence to validate these theories and guide the creation of spaces that promote mental, emotional, and physiological well-being..</p>
                    <p>Our work sits at the intersection of neuroscience, human-computer interaction, and immersive technology, with applications ranging from therapeutic interventions to advanced training simulations and entertainment experiences.</p>
                    
                    <div class="tech-stack">
                        <div class="tech-item">
                            <i class="fas fa-vr-cardboard"></i>
                            <h4>HP Omnicept</h4>
                        </div>
                        <div class="tech-item">
                            <i class="fas fa-brain"></i>
                            <h4>Muse S Athena</h4>
                        </div>
                        <div class="tech-item">
                            <i class="fas fa-code"></i>
                            <h4>Unity/C#</h4>
                        </div>
                        <div class="tech-item">
                            <i class="fas fa-wave-square"></i>
                            <h4>EEG Analysis</h4>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Research Section -->
    <section id="research">
        <div class="container">
            <h2 class="section-title">Research Projects</h2>
            <div class="research-content">
                <div class="research-card">
                    <h3>Biometric Adaptation in VR</h3>
                    <p>Exploring how real-time physiological data from the HP Omnicept system can be used to dynamically adjust VR environments based on user states, creating personalized experiences that respond to cognitive load, attention, and emotional responses.</p>
                    <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10993907/" class="btn" target="_blank">Read Paper</a>
                </div>
                <div class="research-card">
                    <h3>EEG-Controlled Interfaces</h3>
                    <p>Developing novel interaction methods using Muse S Athena EEG data to create thought-controlled navigation in virtual environments. This research has implications for accessibility and hands-free VR interaction paradigms.</p>
                    <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10376313/" class="btn" target="_blank">Read Paper</a>
                </div>
                <div class="research-card">
                    <h3>Emotional Response Mapping</h3>
                    <p>Mapping physiological responses to emotional states in VR to create more empathetic and responsive virtual experiences. This work combines facial expression analysis, GSR, and EEG data to create comprehensive emotional models.</p>
                    <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC8074029/" class="btn" target="_blank">Read Paper</a>
                </div>
                <div class="research-card">
                    <h3>VR in Neurorehabilitation</h3>
                    <p>Investigating the efficacy of virtual reality systems combined with EEG monitoring for neurorehabilitation applications, focusing on motor function recovery and cognitive therapy approaches.</p>
                    <a href="https://www.sciencedirect.com/science/article/pii/S2352710224001797" class="btn" target="_blank">Read Paper</a>
                </div>
                <div class="research-card">
                    <h3>Sensor Integration in VR</h3>
                    <p>Advanced approaches to multi-sensor integration in virtual reality environments, with a focus on EEG data acquisition and its correlation with physiological responses in immersive experiences.</p>
                    <a href="https://www.mdpi.com/1424-8220/22/9/3133" class="btn" target="_blank">Read Paper</a>
                </div>
                <div class="research-card">
                    <h3>Graph Demonstarion</h3>
                    <p>In VR research, EEG is integrated with signals like HRV, fNIRS, and EDA to link brain activity with physiological responses. Graphs such as heatmaps and time-series plots show how EEG bands (alpha, beta, etc.) align with changes in heart rate or stress levels, revealing patterns of immersion and cognitive load. This multi-sensor fusion improves accuracy in tracking user states compared to EEG alone..</p>
                    <a href="https://www.mdpi.com/1424-8220/22/9/3133" class="btn" target="_blank">Figure</a>
                </div>
            </div>
        </div>
    </section>

    <!-- Input/Output Section -->
    <section id="input-output">
        <div class="container">
            <h2 class="section-title">Methodology</h2>
            <div class="io-content">
                <div class="io-item">
                    <div class="io-text">
                        <h3>Input Systems</h3>
                        <p>The research utilizes multi-modal input sources including eye tracking, heart rate variability, EEG brainwave data, and pupillometry from the HP Omnicept system, combined with neural activity data from the Muse S Athena headset.</p>
                        <p>This comprehensive sensor fusion approach allows for a holistic understanding of user states during immersive VR experiences, capturing both conscious and subconscious responses to virtual stimuli.</p>
                    </div>
                    <div class="io-visual">
                        <div class="visual-placeholder">Input Data Visualization</div>
                    </div>
                </div>
                <div class="io-item">
                    <div class="io-text">
                        <h3>Output & Adaptive Systems</h3>
                        <p>The system generates responsive VR environments that adapt in real-time to user states. Outputs include dynamic difficulty adjustment, content personalization, environmental modifications, and emotional response logging.</p>
                        <p>Results demonstrate significant improvements in user engagement, learning outcomes, and emotional connection to virtual experiences compared to static VR environments.</p>
                    </div>
                    <div class="io-visual">
                        <div class="visual-placeholder">Adaptive Output System</div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact Section -->
    <section id="contact">
        <div class="container">
            <h2 class="section-title">Get In Touch</h2>
            <div class="contact-content">
                <div class="contact-form">
                    <form>
                        <div class="form-group">
                            <label for="name">Name</label>
                            <input type="text" id="name" placeholder="Your Name">
                        </div>
                        <div class="form-group">
                            <label for="email">Email</label>
                            <input type="email" id="email" placeholder="Your Email">
                        </div>
                        <div class="form-group">
                            <label for="message">Message</label>
                            <textarea id="message" placeholder="Your Message"></textarea>
                        </div>
                        <button type="submit" class="btn">Send Message</button>
                    </form>
                </div>
                <div class="contact-info">
                    <h3>Contact Information</h3>
                    <p><i class="fas fa-envelope"></i> contact@vrneuralab.com</p>
                    <p><i class="fas fa-phone"></i> +91 9944243910</p>
                    <p><i class="fas fa-map-marker-alt"></i> SRM INSTITUTE OF SCIENCE AND TECHNOLOGY</p>
                    <p><i class="fas fa-link"></i> www.vrneuralab.com</p>

                    <!-- Project Guide Section -->
                    <h3 style="margin-top:30px; color:var(--accent);">Project Guide</h3>
                    <p><i class="fas fa-user-graduate"></i> Dr. T. Jayanthi</p>
                    <p><i class="fas fa-envelope"></i> <a href="mailto:jayantht@srmist.edu.in" style="color: var(--light);">jayantht@srmist.edu.in</a></p>
                    <p><i class="fas fa-university"></i> Associate Professor, Department of Computer Science</p>
                    <p><i class="fas fa-map-marker-alt"></i> SRM Institute of Science and Technology</p>

                    <h3 style="margin-top:30px; color:var(--primary);">Team Members</h3>
                    <p><i class="fas fa-user"></i> Harikant Prasad Gupta (RA2311013010109)</p>
                    <p><i class="fas fa-envelope"></i> <a href="mailto:hg7971@srmist.edu.in" style="color: var(--light);">hg7971@srmist.edu.in</a></p>
                    <p><i class="fas fa-user"></i> Prabal Acharya (RA2311013010108)</p>
                    <p><i class="fas fa-envelope"></i> <a href="mailto:pa1098@srmist.edu.in" style="color: var(--light);">pa1098@srmist.edu.in</a></p>
                    <p><i class="fas fa-user"></i> Kinley Khamsum Tshering (RA2311013010093)</p>
                    <p><i class="fas fa-envelope"></i> <a href="mailto:kt2882@srmist.edu.in" style="color: var(--light);">kt2882@srmist.edu.in</a></p>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="social-links">
                <a href="#"><i class="fab fa-github"></i></a>
                <a href="#"><i class="fab fa-linkedin-in"></i></a>
                <a href="#"><i class="fab fa-twitter"></i></a>
                <a href="#"><i class="fab fa-researchgate"></i></a>
            </div>
            <p>&copy; 2025 VR NeuroLab | Advanced Neuro-Adaptive VR Research</p>
        </div>
    </footer>
    <script src="script.js"></script>
      
    
</body>
</html>